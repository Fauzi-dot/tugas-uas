# -*- coding: utf-8 -*-
"""fixcodeMakalah.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NXoS3sT0uRJYhKR6aTUpe40254jb-bIc
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Load dataset
df = pd.read_csv('OYO Dataset.csv')

# Display the first few rows of the dataset
print(df.head())

# Select relevant features for clustering
features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']
df_features = df[features]

# Standardize the features
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_features)

# Determine the optimal number of clusters using the elbow method
inertia = []
for n in range(1, 11):
    kmeans = KMeans(n_clusters=n, random_state=0)
    kmeans.fit(df_scaled)
    inertia.append(kmeans.inertia_)

plt.figure(figsize=(8, 5))
plt.plot(range(1, 11), inertia, marker='o')
plt.xlabel('Nomor Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Determining Optimal Number of Clusters')
plt.show()

# Apply K-Means with the optimal number of clusters
optimal_clusters = 4  # Example number of clusters based on elbow method
kmeans = KMeans(n_clusters=optimal_clusters, random_state=0)
df['Cluster'] = kmeans.fit_predict(df_scaled)

# Display the first few rows with cluster labels
print(df.head())

# Visualize the clustering results
plt.figure(figsize=(21, 9))
plt.scatter(df['Open'], df['Close'], c=df['Cluster'], cmap='viridis')
plt.xlabel('Open Price')
plt.ylabel('Close Price')
plt.title('Clustering of OYO Stock Prices')
plt.show()

#BAB 4

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Load dataset
df = pd.read_csv('OYO Dataset.csv')

# Select relevant features for clustering
features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']
df_features = df[features]

# Standardize the features
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_features)

# Determine the optimal number of clusters using the elbow method
inertia = []
for n in range(1, 11):
    kmeans = KMeans(n_clusters=n, random_state=0)
    kmeans.fit(df_scaled)
    inertia.append(kmeans.inertia_)

plt.figure(figsize=(8, 5))
plt.plot(range(1, 11), inertia, marker='o')
plt.xlabel('Nomor Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Determining Optimal Number of Clusters')
plt.show()

# Apply K-Means with the optimal number of clusters
optimal_clusters = 4
kmeans = KMeans(n_clusters=optimal_clusters, random_state=0)
df['Cluster'] = kmeans.fit_predict(df_scaled)

# Display the first few rows with cluster labels
print(df.head())

# Visualize the clustering results
plt.figure(figsize=(21, 9))
plt.scatter(df['Open'], df['Close'], c=df['Cluster'], cmap='viridis')
plt.xlabel('Open Price')
plt.ylabel('Close Price')
plt.title('Clustering of OYO Stock Prices')
plt.show()

#METODE ELBOW

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Mengambil dataset dan melakukan scaling pada fitur-fitur yang relevan
df = pd.read_csv('OYO Dataset.csv')
features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']
df_features = df[features]

scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_features)

# Menjalankan K-Means untuk berbagai nilai K dan menghitung WCSS
inertia = []
for n in range(1, 11):
    kmeans = KMeans(n_clusters=n, random_state=0)
    kmeans.fit(df_scaled)
    inertia.append(kmeans.inertia_)

# Memplot hasil WCSS untuk berbagai nilai K
plt.figure(figsize=(8, 5))
plt.plot(range(1, 11), inertia, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia (WCSS)')
plt.title('Elbow Method for Determining Optimal Number of Clusters')
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Load dataset
df = pd.read_csv('OYO Dataset.csv')

# Display the first few rows of the dataset
print(df.head())

# Select relevant features and the target variable
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)

# Assuming 'Close' is the target variable for prediction
df['Prediction'] = df['Close'].shift(-1)
df.dropna(inplace=True)

# Define features (X) and target (y)
X = df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]
y = df['Prediction']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
predictions = model.predict(X_test)

# Calculate the mean squared error
mse = mean_squared_error(y_test, predictions)
print(f'Mean Squared Error: {mse}')

# Plot the results
plt.figure(figsize=(25, 13))
plt.plot(y_test.index, y_test, label='Actual Prices')
plt.plot(y_test.index, predictions, label='Predicted Prices', linestyle='--')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Actual vs Predicted Prices')
plt.legend()
plt.show()

